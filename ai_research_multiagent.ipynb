{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Research Multi-Agent System\n",
    "\n",
    "This notebook demonstrates a multi-agent AI research system using Microsoft Agent Framework (Autogen).\n",
    "\n",
    "## Architecture\n",
    "- **GPT-5.2 Search Agent**: Primary research agent with Bing search grounding\n",
    "- **Grok 4 Search Agent**: Secondary research agent with Bing search grounding\n",
    "- **Claude Mediator**: Arbiter/critique model that cross-questions and validates results\n",
    "\n",
    "## Setup\n",
    "1. Copy `.env.example` to `.env` and fill in your API keys\n",
    "2. Install dependencies: `pip install -r requirements.txt`\n",
    "3. Run this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import json\n",
    "from typing import List, Dict, Any, Optional\n",
    "from dotenv import load_dotenv\n",
    "import autogen\n",
    "from autogen import ConversableAgent, GroupChat, GroupChatManager\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "print(\"Environment loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Set up the LLM configurations for each agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPT-5.2 Configuration (Azure OpenAI)\n",
    "gpt52_config = {\n",
    "    \"config_list\": [\n",
    "        {\n",
    "            \"model\": os.getenv(\"AZURE_OPENAI_GPT_DEPLOYMENT\", \"gpt-52\"),\n",
    "            \"api_type\": \"azure\",\n",
    "            \"api_key\": os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "            \"base_url\": os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "            \"api_version\": os.getenv(\"AZURE_OPENAI_API_VERSION\", \"2024-02-01\"),\n",
    "        }\n",
    "    ],\n",
    "    \"temperature\": 0.7,\n",
    "    \"timeout\": 120,\n",
    "}\n",
    "\n",
    "# Grok 4 Configuration (xAI)\n",
    "grok4_config = {\n",
    "    \"config_list\": [\n",
    "        {\n",
    "            \"model\": os.getenv(\"XAI_GROK_MODEL\", \"grok-4\"),\n",
    "            \"api_key\": os.getenv(\"XAI_API_KEY\"),\n",
    "            \"base_url\": \"https://api.x.ai/v1\",\n",
    "        }\n",
    "    ],\n",
    "    \"temperature\": 0.7,\n",
    "    \"timeout\": 120,\n",
    "}\n",
    "\n",
    "# Claude Configuration (Anthropic)\n",
    "claude_config = {\n",
    "    \"config_list\": [\n",
    "        {\n",
    "            \"model\": os.getenv(\"ANTHROPIC_CLAUDE_MODEL\", \"claude-3-opus-20240229\"),\n",
    "            \"api_key\": os.getenv(\"ANTHROPIC_API_KEY\"),\n",
    "            \"api_type\": \"anthropic\",\n",
    "        }\n",
    "    ],\n",
    "    \"temperature\": 0.5,\n",
    "    \"timeout\": 120,\n",
    "}\n",
    "\n",
    "print(\"Configurations loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bing Search Tool\n",
    "\n",
    "Create a Bing search function for grounding the search agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def bing_search(query: str, count: int = 5) -> str:\n",
    "    \"\"\"\n",
    "    Perform a Bing web search and return results.\n",
    "    \n",
    "    Args:\n",
    "        query: Search query string\n",
    "        count: Number of results to return (default: 5)\n",
    "    \n",
    "    Returns:\n",
    "        Formatted string with search results\n",
    "    \"\"\"\n",
    "    api_key = os.getenv(\"BING_SEARCH_API_KEY\")\n",
    "    endpoint = os.getenv(\"BING_SEARCH_ENDPOINT\", \"https://api.bing.microsoft.com/v7.0/search\")\n",
    "    \n",
    "    if not api_key:\n",
    "        return \"Error: BING_SEARCH_API_KEY not configured\"\n",
    "    \n",
    "    headers = {\"Ocp-Apim-Subscription-Key\": api_key}\n",
    "    params = {\"q\": query, \"count\": count, \"mkt\": \"en-US\"}\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(endpoint, headers=headers, params=params, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        search_results = response.json()\n",
    "        \n",
    "        # Format results\n",
    "        results = []\n",
    "        if \"webPages\" in search_results and \"value\" in search_results[\"webPages\"]:\n",
    "            for idx, result in enumerate(search_results[\"webPages\"][\"value\"], 1):\n",
    "                results.append(\n",
    "                    f\"{idx}. {result['name']}\\n\"\n",
    "                    f\"   URL: {result['url']}\\n\"\n",
    "                    f\"   Snippet: {result.get('snippet', 'N/A')}\\n\"\n",
    "                )\n",
    "        \n",
    "        return \"\\n\".join(results) if results else \"No results found.\"\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"Error performing search: {str(e)}\"\n",
    "\n",
    "# Register the function for use by agents\n",
    "print(\"Bing search function defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Research Agents\n",
    "\n",
    "Define the multi-agent system with specialized roles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPT-5.2 Search Agent\n",
    "gpt_researcher = ConversableAgent(\n",
    "    name=\"GPT_Researcher\",\n",
    "    system_message=\"\"\"You are a primary research agent powered by GPT-5.2.\n",
    "    Your role is to conduct thorough research on given topics using web search.\n",
    "    When researching:\n",
    "    1. Use the bing_search function to find relevant information\n",
    "    2. Analyze and synthesize information from multiple sources\n",
    "    3. Provide well-structured, evidence-based insights\n",
    "    4. Cite your sources clearly\n",
    "    5. Be open to critique and validation from other agents\n",
    "    \"\"\",\n",
    "    llm_config=gpt52_config,\n",
    "    human_input_mode=\"NEVER\",\n",
    ")\n",
    "\n",
    "# Grok 4 Search Agent\n",
    "grok_researcher = ConversableAgent(\n",
    "    name=\"Grok_Researcher\",\n",
    "    system_message=\"\"\"You are a secondary research agent powered by Grok 4.\n",
    "    Your role is to provide alternative perspectives and complementary research.\n",
    "    When researching:\n",
    "    1. Use the bing_search function to find relevant information\n",
    "    2. Focus on different angles than the primary researcher\n",
    "    3. Look for counterarguments and alternative viewpoints\n",
    "    4. Validate or challenge findings from other agents\n",
    "    5. Provide unique insights and analysis\n",
    "    \"\"\",\n",
    "    llm_config=grok4_config,\n",
    "    human_input_mode=\"NEVER\",\n",
    ")\n",
    "\n",
    "# Claude Mediator/Arbiter Agent\n",
    "claude_mediator = ConversableAgent(\n",
    "    name=\"Claude_Mediator\",\n",
    "    system_message=\"\"\"You are a mediator and arbiter powered by Claude.\n",
    "    Your role is to:\n",
    "    1. Cross-question the search agents to probe their findings\n",
    "    2. Identify inconsistencies or gaps in their research\n",
    "    3. Validate results by comparing different agents' outputs\n",
    "    4. Synthesize a final, well-reasoned answer\n",
    "    5. Ask clarifying questions when needed\n",
    "    6. Ensure the research is comprehensive and balanced\n",
    "    \n",
    "    You should be critical, thorough, and impartial in your mediation.\n",
    "    \"\"\",\n",
    "    llm_config=claude_config,\n",
    "    human_input_mode=\"NEVER\",\n",
    ")\n",
    "\n",
    "# User proxy for initiating research\n",
    "user_proxy = ConversableAgent(\n",
    "    name=\"User\",\n",
    "    system_message=\"You are a user who initiates research tasks.\",\n",
    "    llm_config=False,  # No LLM needed for user proxy\n",
    "    human_input_mode=\"NEVER\",\n",
    "    is_termination_msg=lambda msg: \"TERMINATE\" in msg.get(\"content\", \"\"),\n",
    ")\n",
    "\n",
    "# Register the bing_search function with all agents\n",
    "for agent in [gpt_researcher, grok_researcher, claude_mediator]:\n",
    "    agent.register_for_llm(\n",
    "        name=\"bing_search\",\n",
    "        description=\"Search the web using Bing to find relevant information on a topic.\"\n",
    "    )(bing_search)\n",
    "\n",
    "for agent in [user_proxy]:\n",
    "    agent.register_for_execution(name=\"bing_search\")(bing_search)\n",
    "\n",
    "print(\"Agents created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up Group Chat\n",
    "\n",
    "Create a group chat where agents can collaborate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create group chat\n",
    "group_chat = GroupChat(\n",
    "    agents=[user_proxy, gpt_researcher, grok_researcher, claude_mediator],\n",
    "    messages=[],\n",
    "    max_round=12,\n",
    "    speaker_selection_method=\"auto\",\n",
    ")\n",
    "\n",
    "# Create group chat manager\n",
    "manager = GroupChatManager(\n",
    "    groupchat=group_chat,\n",
    "    llm_config=gpt52_config,  # Use GPT-5.2 for managing the conversation flow\n",
    ")\n",
    "\n",
    "print(\"Group chat configured!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research Function\n",
    "\n",
    "Main function to conduct research on a given topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conduct_research(topic: str, max_rounds: int = 12) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Conduct multi-agent research on a given topic.\n",
    "    \n",
    "    Args:\n",
    "        topic: Research topic/question\n",
    "        max_rounds: Maximum number of conversation rounds\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary containing research results and conversation history\n",
    "    \"\"\"\n",
    "    # Update group chat max rounds\n",
    "    group_chat.max_round = max_rounds\n",
    "    \n",
    "    # Initiate the research\n",
    "    research_prompt = f\"\"\"\n",
    "    Research Topic: {topic}\n",
    "    \n",
    "    Instructions for the team:\n",
    "    1. GPT_Researcher: Begin by searching for and analyzing information on this topic\n",
    "    2. Grok_Researcher: Provide complementary research and alternative perspectives\n",
    "    3. Claude_Mediator: Cross-question both researchers, validate findings, and synthesize final answer\n",
    "    \n",
    "    Please collaborate to provide a comprehensive, well-researched answer.\n",
    "    End with \"TERMINATE\" when the research is complete.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Start the conversation\n",
    "    chat_result = user_proxy.initiate_chat(\n",
    "        manager,\n",
    "        message=research_prompt,\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        \"topic\": topic,\n",
    "        \"chat_history\": chat_result.chat_history,\n",
    "        \"summary\": chat_result.summary,\n",
    "    }\n",
    "\n",
    "print(\"Research function ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Conduct Research\n",
    "\n",
    "Let's research a topic using our multi-agent system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example research topic\n",
    "research_topic = \"What are the latest advancements in quantum computing in 2024?\"\n",
    "\n",
    "print(f\"Starting research on: {research_topic}\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Conduct the research\n",
    "results = conduct_research(research_topic, max_rounds=15)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"Research Complete!\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View Research Results\n",
    "\n",
    "Display the conversation and final summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display chat history\n",
    "print(\"\\nConversation History:\")\n",
    "print(\"=\" * 80)\n",
    "for i, message in enumerate(results[\"chat_history\"], 1):\n",
    "    speaker = message.get(\"name\", \"Unknown\")\n",
    "    content = message.get(\"content\", \"\")\n",
    "    print(f\"\\n[{i}] {speaker}:\")\n",
    "    print(\"-\" * 80)\n",
    "    print(content)\n",
    "    print()\n",
    "\n",
    "# Display summary\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"Summary:\")\n",
    "print(\"=\" * 80)\n",
    "print(results.get(\"summary\", \"No summary available\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Research Query\n",
    "\n",
    "Use this cell to research your own topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your research question here\n",
    "my_topic = \"Your research question here\"\n",
    "\n",
    "# Uncomment to run\n",
    "# my_results = conduct_research(my_topic, max_rounds=15)\n",
    "# print(\"Research complete! Check the results above.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Results\n",
    "\n",
    "Save research results to a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "def save_research_results(results: Dict[str, Any], filename: Optional[str] = None):\n",
    "    \"\"\"\n",
    "    Save research results to a JSON file.\n",
    "    \n",
    "    Args:\n",
    "        results: Research results dictionary\n",
    "        filename: Output filename (defaults to timestamped file)\n",
    "    \"\"\"\n",
    "    if filename is None:\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        filename = f\"research_results_{timestamp}.json\"\n",
    "    \n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(results, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    print(f\"Results saved to: {filename}\")\n",
    "\n",
    "# Example: Save the results\n",
    "# save_research_results(results)\n",
    "print(\"Export function ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Configuration\n",
    "\n",
    "Customize agent behavior and conversation flow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can modify agent configurations here\n",
    "# For example, adjust temperature, add custom system messages, etc.\n",
    "\n",
    "def create_custom_researcher(name: str, system_message: str, config: Dict[str, Any]):\n",
    "    \"\"\"\n",
    "    Create a custom research agent with specific configuration.\n",
    "    \n",
    "    Args:\n",
    "        name: Agent name\n",
    "        system_message: Custom system message\n",
    "        config: LLM configuration\n",
    "    \n",
    "    Returns:\n",
    "        ConversableAgent instance\n",
    "    \"\"\"\n",
    "    agent = ConversableAgent(\n",
    "        name=name,\n",
    "        system_message=system_message,\n",
    "        llm_config=config,\n",
    "        human_input_mode=\"NEVER\",\n",
    "    )\n",
    "    \n",
    "    # Register search function\n",
    "    agent.register_for_llm(\n",
    "        name=\"bing_search\",\n",
    "        description=\"Search the web using Bing to find relevant information.\"\n",
    "    )(bing_search)\n",
    "    \n",
    "    return agent\n",
    "\n",
    "print(\"Custom agent creation function ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Troubleshooting\n",
    "\n",
    "Common issues and solutions:\n",
    "\n",
    "1. **API Key Errors**: Ensure all API keys are properly set in your `.env` file\n",
    "2. **Search Not Working**: Verify Bing Search API key and endpoint are correct\n",
    "3. **Timeout Errors**: Increase the `timeout` value in agent configurations\n",
    "4. **Rate Limits**: Add delays between requests if hitting API rate limits\n",
    "\n",
    "For more help, refer to:\n",
    "- [Microsoft AutoGen Documentation](https://microsoft.github.io/autogen/)\n",
    "- [Azure AI Documentation](https://learn.microsoft.com/azure/ai-services/)\n",
    "- [Anthropic Claude API](https://docs.anthropic.com/)\n",
    "- [xAI Documentation](https://docs.x.ai/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
